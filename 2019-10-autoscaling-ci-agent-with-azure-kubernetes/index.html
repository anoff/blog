<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Andreas Offenhaeuser"><meta name=description content="Andreas' personal blog"><meta name=keywords content=blog,personal,software,architecture,node,markdown,plantuml,developer><meta name=generator content="Hugo 0.55.6"><title>Building autoscaling CI infrastructure with Azure Kubernetes | Andreas&#39; Blog</title><meta name=description content="Building autoscaling CI infrastructure with Azure Kubernetes - Andreas' personal blog"><meta itemprop=name content="Building autoscaling CI infrastructure with Azure Kubernetes"><meta itemprop=description content="Building autoscaling CI infrastructure with Azure Kubernetes - Andreas' personal blog"><meta property=og:title content="Building autoscaling CI infrastructure with Azure Kubernetes"><meta property=og:description content="Building autoscaling CI infrastructure with Azure Kubernetes - Andreas' personal blog"><meta property=og:image content=/assets/scaling-agents-aks/title.png><meta property=og:url content=//blog.anoff.io/2019-10-autoscaling-ci-agent-with-azure-kubernetes/><meta property=og:site_name content="Andreas' Blog"><meta property=og:type content=article><link rel=icon type=image/png href=//blog.anoff.io/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=//blog.anoff.io/favicon-16x16.png sizes=16x16><link href=/2019-10-autoscaling-ci-agent-with-azure-kubernetes/ rel=alternate type=application/rss+xml title="Andreas' Blog"><link href=/2019-10-autoscaling-ci-agent-with-azure-kubernetes/ rel=feed type=application/rss+xml title="Andreas' Blog"><link rel=stylesheet href=/sass/combined.min.f327a75a4aad18c5bec7b5dd7b51a776643885a0f7cca521b438abae302cc24d.css><link rel=stylesheet href=//blog.anoff.io/adoc.css><link rel=stylesheet href=//blog.anoff.io/overwrites.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css></head><body class=bilberry-hugo-theme><nav class=permanentTopNav><div class=container><ul class=topnav><li><a href=//anoff.io/ target=_self>About me</a></li><li><a href=/ target=_self>Blog</a></li><li><a href=//anoff.io/project/ target=_self>Projects</a></li><li><a href=/tags target=_self>by Tags</a></li><li><a href=//radar.anoff.io target=_blank>Tech skills</a></li><li><a href=//anoff.github.io/legal/ target=_blank>Legal</a></li></ul></div></nav><header><div class=container><div class=logo><a href=//blog.anoff.io/ class=logo><img src=/avatar.png alt>
<span class=overlay><i class="fa fa-child"></i></span></a></div><div class=titles><h3 class=title><a href=//blog.anoff.io/>Andreas&#39; Blog</a></h3><span class=subtitle>Adventures of a software engineer/architect</span></div><div class="toggler permanentTopNav"><i class="fa fa-bars" aria-hidden=true></i></div></div></header><div class="main container"><div class="article-wrapper u-cf single"><a class=bubble href=//blog.anoff.io/2019-10-autoscaling-ci-agent-with-azure-kubernetes/><i class="fa fa-fw fa-code"></i></a><article class="default article"><div class=featured-image><a href=//blog.anoff.io/2019-10-autoscaling-ci-agent-with-azure-kubernetes/><img src=/assets/scaling-agents-aks/title.png alt></a></div><div class=content><h3><a href=//blog.anoff.io/2019-10-autoscaling-ci-agent-with-azure-kubernetes/>Building autoscaling CI infrastructure with Azure Kubernetes</a></h3><div class=meta><span class="date moment">2019-10-17</span>
<span class=readingTime>9 min read</span>
<span class=author><a href=/author/anoff>anoff</a></span></div><p>In a previous blog post <a href=/2019-08-24-drone-ci-travis-ci-to-azure-pipelines/>Migrating to Azure Pipelines</a> I gave an introduction to the Azure CI/CD service from a user perspective.
With this post I want to share my experience while setting up a dedicated CI runner infrastructure with the Azure + Pipelines ecosystem.
Basic knowledge of <code>Docker</code> and <code>Kubernetes</code> should exists - you should know what they are.
The main features of the solution are ephemeral build agents, docker based environments, minimal operation responsible and strong pay-per-use billing concepts.</p><section class="doc-section level-1"><h2 id=_why_build_auto_scaling_ci_infrastructure><a class=link href=#_why_build_auto_scaling_ci_infrastructure>Why build auto scaling CI infrastructure</a></h2><p>You might ask <em>Why do you want to build a custom solution for auto-scaling CI infrastructure? There is already X out there</em>.</p><p>The easy answer: <em>To learn how things work</em></p><p>The real answer: I could not find a CI system that fulfills all my requirements.
What I need the CI infrastructure to be capable of:</p><div class="olist arabic"><ol class=arabic><li>provide real <em>pay per use</em></li><li>support Linux and Windows agents</li><li>run on specific VMs with special hardware requirements (CPU, GPU, Memory, disks)</li><li>share specific volumes between all runners e.g. cache files</li><li>scale up to 20+ of agents</li><li>everything as code</li><li>state of the art UI with active directory authentication</li><li>scale down to as little agents as possible to reduce costs</li><li>minimal responsibility; as little code and operational efforts as possible</li></ol></div></section><section class="doc-section level-1"><h2 id=_the_black_box_solution><a class=link href=#_the_black_box_solution>The black box solution</a></h2><p>With the goal of not managing everything myself I chose Azure Pipelines as CI environment.
It also supports the requirements 1-4 by running arbitrary bash scripts within a pipeline as described in my <a href=/2019-08-24-drone-ci-travis-ci-to-azure-pipelines/>previous post</a>.</p><p>Given the list of requirements the solution can be described with the following picture.</p><div class=image-block><img src=/assets/scaling-agents-aks/blackbox.png alt="A new job triggers the creation of a new CI agent"></div><p>With Azure Pipelines as the CI system in place the open variables are knowing how many agents to host, manage their lifecycle and how to host them.</p></section><section class="doc-section level-1"><h2 id=_hosting_the_build_agent><a class=link href=#_hosting_the_build_agent>Hosting the build agent</a></h2><p>There are two ways to host your own agents for Azure Pipelines.
One is getting the client code and put it on your virtual machine which is described in <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/v2-linux?view=azure-devops">"Self-hosted Linux agents"</a> article in the azure documentation.
The alternative is running it within a <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/docker?view=azure-devops">docker container</a>.
I decided to run the agent in a docker container because having docker as the only dependency on the host offers a wider solution space.
The Dockerfile below is taken from the <a href="https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/docker?view=azure-devops#linux">Azure docs</a>.</p><figure class=listing-block><figcaption>Dockerfile for Azure Pipelines agent</figcaption><pre class="CodeRay highlight"><code data-lang=docker>FROM ubuntu:16.04

# To make it easier for build and release pipelines to run apt-get,
# configure apt to not require confirmation (assume the -y argument by default)
ENV DEBIAN_FRONTEND=noninteractive
ENV DOCKER_VERSION=&quot;18.03.1-ce&quot;
RUN echo &quot;APT::Get::Assume-Yes \&quot;true\&quot;;&quot; &gt; /etc/apt/apt.conf.d/90assumeyes

RUN apt-get update \
    &amp;&amp; apt-get install -y --no-install-recommends \
        ca-certificates \
        curl \
        jq \
        git \
        iputils-ping \
        libcurl3 \
        libicu55 \
        libunwind8 \
        netcat

# add docker CLI
RUN curl -fsSL https://download.docker.com/linux/static/stable/x86_64/docker-$DOCKER_VERSION.tgz | \
    tar zxvf - --strip 1 -C /usr/bin docker/docker

WORKDIR /azp

COPY ./start.sh ./start-once.sh ./
RUN chmod +x start.sh start-once.sh</code></pre></figure><p>To actually run this dockerized build agent there are multiple options available on Azure.</p><figure class=table-block><figcaption>Table 1. Docker host options</figcaption><table class="frame-all grid-all spread"><col style=width:25%><col style=width:25%><col style=width:25%><col style=width:25%><thead><tr><th class="halign-left valign-top">Solution</th><th class="halign-left valign-top">Description</th><th class="halign-left valign-top">Challenge</th><th class="halign-left valign-top">Â Advantage</th></tr><tbody><tr><td class="halign-left valign-top"><a href=https://azure.microsoft.com/en-us/services/virtual-machines/>Virtual Machine</a></td><td class="halign-left valign-top">Using a simple virtual machine with the docker engine installed agents can be started</td><td class="halign-left valign-top">Scaling the VMs up and down; operational effort</td><td class="halign-left valign-top">very simple solution</td></tr><tr><td class="halign-left valign-top"><a href=https://azure.microsoft.com/en-us/services/virtual-machine-scale-sets/>Virtual Machine Scale Set (VMSS)</a></td><td class="halign-left valign-top">VMSS allows creating multiple identical machines via an easy API e.g. count=4</td><td class="halign-left valign-top">when scaling down, Azure might pick a VM that is still actively running an agent/job</td><td class="halign-left valign-top">solves the scaling issue that VMs have</td></tr><tr><td class="halign-left valign-top"><a href=https://azure.microsoft.com/en-us/services/kubernetes-service/>Azure Kubernetes Service (AKS)</a></td><td class="halign-left valign-top">a managed Kubernetes environment for running docker containers</td><td class="halign-left valign-top">need to orchestrate agent in Kubernetes</td><td class="halign-left valign-top">little operation responsibility and full control over hardware spec</td></tr><tr><td class="halign-left valign-top"><a href=https://azure.microsoft.com/en-us/services/app-service/containers/>Azure WebApp for Containers</a></td><td class="halign-left valign-top">run docker containers on a previously specified VM type without interacting with the VM directly</td><td class="halign-left valign-top">same as VMSS</td><td class="halign-left valign-top">abstracts VM and thereby reduces operational responsibility</td></tr><tr><td class="halign-left valign-top"><a href=https://azure.microsoft.com/en-us/services/container-instances/>Azure Container Instances (ACI)</a></td><td class="halign-left valign-top">run a docker container inside a fully managed docker environment</td><td class="halign-left valign-top">does not allow to specify VM type (only CPU count)</td><td class="halign-left valign-top">least operational responsibility</td></tr></table></figure></section><section class="doc-section level-1"><h2 id=_cluster_autoscaler><a class=link href=#_cluster_autoscaler>Cluster Autoscaler</a></h2><p>I chose to run on Azure Kubernetes Service (AKS) because using the right configuration it allows me to implement the <strong>pay per use</strong> and <strong>scalability</strong> almost out of the box.
The key feature to achieve this is <a href=https://docs.microsoft.com/en-us/azure/aks/cluster-autoscaler>Cluster Autoscaler</a>.
Using Virtual Machine Scale Sets (VMSS) for the Kubernetes nodes this feature checks if there are enough resources in the cluster to host all pods.</p><aside class="admonition-block note" role=note><h6 class="block-title label-only"><span class=title-label>Note:</span></h6><p>A pod in Kubernetes is a group of Docker containers that are run together on the same host</p></aside><p>If necessary the cluster autoscaler adds additional virtual machines to the Kubernetes cluster or removes them if they are idle for too long (~10minutes).
In the following scenario each build agent is run in a separate pod.
Each pod occupies so many resources as a single VM can provide.
Thus if a new build agent is needed, one new VM will be needed.</p><figure class=image-block><img src=/assets/scaling-agents-aks/cluster-autoscaler-comp.png alt="cluster autoscaler comp" width=624 height=280><figcaption>Figure 1. Components involved in the Cluster Autoscaler</figcaption></figure><figure class=image-block><img src=/assets/scaling-agents-aks/cluster-autoscaler-seq.png alt="cluster autoscaler seq" width=687 height=849><figcaption>Figure 2. How the cluster autoscaler works</figcaption></figure><p>Another reason I chose the AKS solution is the fact that I am a bit familiar with Kubernetes and Helm charts as ways of describing the system in code.
With <strong>automation</strong> being another high level requirement I was worried that container instances and web apps might be a bit difficult to orchestrate throughout their lifecycle.
Using AKS as a runtime for the agent fulfills the following requirements:</p><div class="olist arabic"><ol class=arabic><li>â provide real <em>pay per use</em> where idle time is reduced</li><li>â ï¸ support Linux and Windows agents: <em>Would require a separate node pool running <a href=https://docs.microsoft.com/en-us/azure/aks/windows-node-limitations>Windows nodes</a></em></li><li>â run on specific VMs with special hardware requirements (CPU, GPU, disks)</li><li>â ï¸ share specific volumes between all runners e.g. cache files: <em>depending on the Helm configuration this is possible</em></li><li>â scale up to 20+ of agents</li><li>â everything as code</li><li>â state of the art UI with active directory authentication: <em>achieved by choosing Azure Pipelines as CI orchestrator</em></li><li>â scale down to as little agents as possible to reduce costs</li><li>â minimal responsibility; as little code and operational efforts as possible</li></ol></div><aside class="admonition-block note" role=note><h6 class="block-title label-only"><span class=title-label>Note:</span></h6><p>The exact implementation in Kubernetes will be part of a follow-up blog post</p></aside></section><section class="doc-section level-1"><h2 id=_identifying_agent_demand><a class=link href=#_identifying_agent_demand>Identifying agent demand</a></h2><p>To know how many build agents need to be running in the cluster we need to get information from Azure Pipelines about the number of <code>active jobs</code>.
Active is defined as:</p><div class=example-block><div class=example><p>active jobs = running jobs (already using an agent) + pending jobs (waiting for an agent to be assigned)</p></div></div><p>Sadly there are no webhooks available in Azure Pipelines that trigger when a new build job is being started.
That is why I resorted to polling the Azure Pipelines API to get information about the build status.
This can either be done with the HTTP API directly or using the <strong>Azure CLI</strong>.
After installing the Azure CLI, an additional extension is needed to work with the Azure Pipelines (Azure DevOps) API.</p><div class=listing-block><pre class="CodeRay highlight"><code data-lang=bash>az extension add --name azure-devops</code></pre></div><p>The Azure Pipelines API is RESTful and therefore you need to get information per <strong>Azure DevOps organization</strong> and <strong>project</strong>.
Each project may host multiple repositories and Azure Pipelines.
So depending on your project setup this part of the solution might need to be adapted to identify the actual build jobs that can be handled by the agents deployed in the cluster.</p><div class=listing-block><pre class="CodeRay highlight"><code data-lang=bash>az pipelines build list --organization 'https://dev.azure.com/anoff' --project 'AKS build test' --status=notStarted|inProgress -o json</code></pre></div><aside class="admonition-block note" role=note><h6 class="block-title label-only"><span class=title-label>Note:</span></h6><p>You can only use one of the <code>status</code> values per request
To get all <code>active jobs</code> you need to run the command twice and add both numbers.</p></aside></section><section class="doc-section level-1"><h2 id=_scaling_to_the_correct_amount_of_agents><a class=link href=#_scaling_to_the_correct_amount_of_agents>Scaling to the correct amount of agents</a></h2><p>This is the part where things got a little tricky.
The provided <strong>Cluster Autoscaler</strong> for AKS only takes care of scaling underlying resources.
To allow resources to scale we need to remove/add build agent pods based on the active jobs.
When there are more jobs than pod it should be rather easy to add more pods to the cluster.
However when there are more pods (build agents) than there are active build jobs the solution needs to scale down.
While some build agents are actively running jobs this is a stateful scenario where we want to identify exactly which pod should be taken down because its corresponding build agent is currently not actively running a build job.</p><div class=quote-block><blockquote><p>Kubernetes becomes extremely complicated if your solution is not stateless</p></blockquote></div><p>In this scenario stateless means that we can treat all build agents the same.
This is only true at a point where there are no active jobs in the system.
But that point is also when all agents can be removed completely.
Without an additional scale-down solution that would mean the cluster increasing in size and only scaling down once no builds are running.
While this may work over a larger time window it was a too big trade-off for me to already be satisfied with it.</p><p>The solution to this problem was combining the configuration options that the Azure Pipelines agent brings with the type of workloads that Kubernetes can run.
My initial approach was to run <strong>StatefulSet</strong> in Kubernetes that allow running pods with mounted volumes (see requirements).
However using the <strong>Batch Jobs</strong> API of Kubernetes it is possible to spawn pods that only run until the process inside the pod ends.
Luckily there is a <code>--once</code> flag when staring an Azure Pipelines agent that terminates the agent after one job has been handled.
This means that the number of <code>active jobs</code> just needs to be identical to the number of <strong>Batch Jobs</strong> inside the AKS cluster.
After the build jobs are done the pod is automatically removed from the cluster and the <strong>Cluster Autoscaler</strong> will take care of removing the underlying hardware (VMSS) after it has been idling long enough.
This scale-down scenario is really nice because it requires no state handling from the outside regarding the lifecycle of individual agents.
Instead all agents share an identical, ephemeral, short lifecycle:</p><div class=quote-block><blockquote><p>All agents are treated the same; they start, they run a single job, they stop, they get terminated.</p></blockquote></div><figure class=image-block><img src=/assets/scaling-agents-aks/pod-lifecycle.svg alt="pod lifecycle" width=234 height=527><figcaption>Figure 3. Pipeline agent lifecycle</figcaption></figure><p>To trigger the creation of new pipeline agents via the kubernets <strong>BatchJob</strong> API I wrote a small python script that identifies the number of <code>active jobs</code> and compares it with the number of agent pods running in AKS.
For any additional job a new <strong>BatchJob</strong> is started via <code>Helm</code>.
The script itself is running inside Kubernetes in a <strong>CronJob</strong> that gets executed once per minute.</p><figure class=image-block><img src=/assets/scaling-agents-aks/kubernetes-scaler.png alt="kubernetes scaler" width=543 height=499><figcaption>Figure 4. Kubernetes setup</figcaption></figure></section><section class="doc-section level-1"><h2 id=_putting_it_all_together><a class=link href=#_putting_it_all_together>Putting it all together</a></h2><p>All parts of the puzzle seemed to be solved.
The above sections describe how to</p><div class="olist arabic"><ol class=arabic><li>host a dockerized Azure Pipelines agent</li><li>identify how many agents are needed</li><li>automatically scale the underlying infrastructure (= cost)</li><li>deal with the lifecycle problem of the agents</li></ol></div><p>In addition all initial requirements are fulfilled.
The solution I cam up with is pictured below</p><figure class=image-block><img src=/assets/scaling-agents-aks/solution.png alt="Overview of the solution"><figcaption>Figure 5. Overview of the solution</figcaption></figure><p>In a follow up blog post I will provide some implementation details.
If you are interested in any specific parts please leave a comment or contact me via <a href=https://twitter.com/anoff_io>Twitter</a> ð</p></section></div><div class=footer><div class=tags><i class="fa fa-tags"></i><div class=links><a href=/tags/ci/cd>CI/CD</a>
<a href=/tags/azure>azure</a>
<a href=/tags/docker>docker</a></div></div></div></article></div><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"anoff-io"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><footer><div class=container><div class=right><div class=external-profiles><strong>Social media</strong>
<a href=//twitter.com/anoff_io target=_blank><i class="fa fa-twitter-adblock-proof"></i></a><a href=//github.com/anoff target=_blank><i class="fa fa-github"></i></a><a href=//linkedin.com/in/offenhaeuser/ target=_blank><i class="fa fa-linkedin"></i></a></div></div></div></footer><div class=credits><div class=container><div class=copyright><a href=//anoff.io target=_blank>&copy;
2019
by Andreas Offenhaeuser</a></div><div class=author><a href=//github.com/Lednerb/bilberry-hugo-theme target=_blank>Bilberry Hugo Theme</a></div></div></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-93890295-4','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src=/js/externalDependencies.39c47e10e241eae2947b3fe21809c572.js integrity="md5-OcR&#43;EOJB6uKUez/iGAnFcg=="></script><script type=text/javascript src=/js/theme.ff50ae6dc1bfc220b23bf69dbb41b54e.js integrity="md5-/1CubcG/wiCyO/adu0G1Tg=="></script><script>$(".moment").each(function(){$(this).text(moment($(this).text()).locale("en").format('LL'));});$(".footnote-return sup").html("");</script><script src=//blog.anoff.io/fix-adoc.js type=application/javascript></script><script src=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js type=application/javascript></script><script src=//blog.anoff.io/init-cookieconsent.js type=application/javascript></script></body></html>