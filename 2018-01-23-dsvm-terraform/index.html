<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Andreas Offenhaeuser"><meta name=description content="Andreas' personal blog"><meta name=keywords content=blog,personal,software,architecture,node,markdown,plantuml,developer><meta name=generator content="Hugo 0.54.0"><title>Deploy Datascience infrastructure on Azure using Terraform | Andreas&#39; Blog</title><meta name=description content="Deploy Datascience infrastructure on Azure using Terraform - Andreas' personal blog"><meta itemprop=name content="Deploy Datascience infrastructure on Azure using Terraform"><meta itemprop=description content="Deploy Datascience infrastructure on Azure using Terraform - Andreas' personal blog"><meta property=og:title content="Deploy Datascience infrastructure on Azure using Terraform"><meta property=og:description content="Deploy Datascience infrastructure on Azure using Terraform - Andreas' personal blog"><meta property=og:image content="https://www.gravatar.com/avatar/d41d8cd98f00b204e9800998ecf8427e?size=200"><meta property=og:url content=//blog-gh.anoff.io/2018-01-23-dsvm-terraform/><meta property=og:site_name content="Andreas' Blog"><meta property=og:type content=article><link rel=icon type=image/png href=//blog-gh.anoff.io/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=//blog-gh.anoff.io/favicon-16x16.png sizes=16x16><link rel=stylesheet href=/sass/combined.min.907b81d5af3487ae16374539a98ecad040518176b022bfbee78923b1b8cab4d3.css><link rel=stylesheet href=//blog-gh.anoff.io/adoc.css><link rel=stylesheet href=//blog-gh.anoff.io/overwrites.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.css></head><body class=bilberry-hugo-theme><nav class=permanentTopNav><div class=container><ul class=topnav><li><a href=//anoff.io/ target=_blank>About me</a></li><li><a href=/tags target=_self>by Tags</a></li><li><a href=//anoff.io/legal target=_blank>Legal</a></li></ul></div></nav><header><div class=container><div class=logo><a href=//blog-gh.anoff.io class=logo><img src=/avatar.png alt>
<span class=overlay><i class="fa fa-child"></i></span></a></div><div class=titles><h3 class=title><a href=//blog-gh.anoff.io>Andreas&#39; Blog</a></h3><span class=subtitle>Adventures of a software engineer/architect</span></div><div class="toggler permanentTopNav"><i class="fa fa-bars" aria-hidden=true></i></div></div></header><div class="main container"><div class="article-wrapper u-cf single"><a class=bubble href=/2018-01-23-dsvm-terraform/><i class="fa fa-fw fa-pencil"></i></a><article class="default article"><div class=content><h3><a href=/2018-01-23-dsvm-terraform/>Deploy Datascience infrastructure on Azure using Terraform</a></h3><div class=meta><span class="date moment">2018-01-23</span>
<span class=readingTime>6 min read</span>
<span class=author><a href=/author/anoff>anoff</a></span></div><p>In this article I will talk about my experience building my first infrastructure deployment using Terraform that does (a little) more than combining off-the-shelf resources.</p><h1 id=the-stack-we-will-deploy>The stack we will deploy üì¶</h1><p>Lately I‚Äôve been looking at a lot of Microsoft Azure services in the big data area. I am looking for something to replace a Hadoop based üêò data analytics environment consisting mainly of HDFS, Spark &amp; Jupyter.</p><p><img src=/assets/terraform-dsvm/logo.png alt="How to Datascience on Azure?"></p><p>The most obvious solution is to use a <a href=https://azure.microsoft.com/en-us/services/hdinsight/>HDInsight cluster</a> which is basically a managed Hadoop that you can pick in different flavours. However with the elasticity of the cloud at my hands I wanted to go for a more diverse setup that also allows a pure #python üêç based data science stack without the need to use Spark. One reason for this is that many use cases do not require a calculation on all of the data but just use spark to mask the data. For the actual analysis/training the amount of data often fits in RAM‚Ää‚Äî‚Ääif I get a bit more than my MacBook Pro has to offer üôÑ. The solution described in this article consists of a <a href=https://docs.microsoft.com/en-us/azure/machine-learning/data-science-virtual-machine/overview>Data Science Virtual Machine</a> üñ• and <a href=https://docs.microsoft.com/en-us/azure/storage/files/storage-files-introduction>Azure Files</a> üìÑ for common data store. As the file storage account has a cap on 5TB you might need something different if you really have a lot of data‚Ää‚Äî‚Ääor use multiple fileshares.</p><p><img src=/assets/terraform-dsvm/shared_storage.png alt="Multiple VMs accessing a shared storage"></p><blockquote><p>Target setup with multiple data scientist VM accessing a common data pool</p></blockquote><h1 id=quick-intro-to-terraform>Quick intro to Terraform üëÄ</h1><blockquote><p>Terraform is a tool for building, changing, and versioning infrastructure safely and efficiently. [‚Ä¶] Terraform generates an execution plan describing what it will do to reach the desired state, and then executes it to build the described infrastructure. As the configuration changes, Terraform is able to <strong>determine what changed and create incremental execution plans</strong> which can be applied.</p></blockquote><p><a href=https://en.wikipedia.org/wiki/Infrastructure_as_Code>Infrastructure as Code (IaC)</a> is an important aspect for me when managing a cloud solution. I want to be able to automate ‚öôÔ∏è everything from infrastructure provisioning to code deployment. Amazon Web Services has Cloudformation, Azure has the Azure Resource Manager (ARM) templates but <a href=https://www.terraform.io/intro/index.html>Hashicorps Terraform</a> provides a somewhat cloud agnostic layer on top of those proprietary tools. &lsquo;<em>Somewhat</em>&rsquo; because the recipes you write are specific to a certain cloud environment but it allows you to use common syntax to deploy a multi-cloud solution. The main reason for me to use Terraform instead of ARM is that it offers a better way to create modular recipes and not worry about handling the state during incremental deployments.</p><h1 id=building-the-terraform-recipe>Building the Terraform recipe üìú</h1><p>When deploying any higher level components the first thing to do is figure out what underlying infrastructure is used. The easiest way to do this is click yourself through the Portal to create the resource‚Ää‚Äî‚Ääin this case the Data Scientist VM‚Ää‚Äî‚Ääand look at the ARM template that drops out of this process. You could use it to deploy this VM automatically using either the ARM tooling or the <a href=https://www.terraform.io/docs/providers/azurerm/r/template_deployment.html>azurerm_template_deployment</a> in Terraform. However the ARM templates are way too complex to maintain to my liking.</p><p><img src=/assets/terraform-dsvm/portal_deploy.png alt="Access ARM template from portal"></p><p><img src=/assets/terraform-dsvm/arm_view.png alt="Overview of ARM resources"></p><blockquote><p>Resource view of the ARM template in Azure Portal</p></blockquote><p>In the case of the Data Scientist VM you can see that five different resources are deployed to bring up an Azure VM. The machine itself which consists of compute and memory allocations. A storage account that holds the disk images and a couple of networking components.</p><p>If you look at the <a href=https://www.terraform.io/docs/providers/azurerm/r/virtual_machine.html>Virtual Machine recipe that is available on the Terraform docs</a> you may see similar components. There they are called _azurerm_virtual<em>network</em>, _azurerm<em>subnet</em>, _azurerm_network<em>interface</em>, _azurerm_virtual<em>machine</em>. I took the Terraform example as a base for my recipe and tried to modify this vanilla Ubuntu VM into the Data Science VM that I clicked together using the Portal. So I was mostly interested in figuring out what part of the VM deployment makes the VM a Data Science VM with all those fancy software packages pre-installed.</p><pre><code class=language-json>  &quot;resources&quot;: [
  {
      &quot;name&quot;: &quot;[parameters('virtualMachineName')]&quot;,
      &quot;type&quot;: &quot;Microsoft.Compute/virtualMachines&quot;,
      &quot;apiVersion&quot;: &quot;2016-04-30-preview&quot;,
      &quot;location&quot;: &quot;[parameters('location')]&quot;,
      &quot;dependsOn&quot;: [
          &quot;[concat('Microsoft.Network/networkInterfaces/', parameters('networkInterfaceName'))]&quot;,
          &quot;[concat('Microsoft.Storage/storageAccounts/', parameters('diagnosticsStorageAccountName'))]&quot;
      ],
      &quot;properties&quot;: {
          &quot;osProfile&quot;: {
              &quot;computerName&quot;: &quot;[parameters('virtualMachineName')]&quot;,
              &quot;adminUsername&quot;: &quot;[parameters('adminUsername')]&quot;,
              &quot;adminPassword&quot;: &quot;[parameters('adminPassword')]&quot;
          },
          &quot;hardwareProfile&quot;: {
              &quot;vmSize&quot;: &quot;[parameters('virtualMachineSize')]&quot;
          },
          &quot;storageProfile&quot;: {
              &quot;imageReference&quot;: {
                  &quot;publisher&quot;: &quot;microsoft-ads&quot;,
                  &quot;offer&quot;: &quot;linux-data-science-vm-ubuntu&quot;,
                  &quot;sku&quot;: &quot;linuxdsvmubuntu&quot;,
                  &quot;version&quot;: &quot;latest&quot;
              },
              &quot;osDisk&quot;: {
                  &quot;createOption&quot;: &quot;fromImage&quot;,
                  &quot;managedDisk&quot;: {
                      &quot;storageAccountType&quot;: &quot;Premium_LRS&quot;
                  }
              },
              &quot;dataDisks&quot;: [
                  {
                      &quot;createOption&quot;: &quot;fromImage&quot;,
                      &quot;lun&quot;: 0,
                      &quot;managedDisk&quot;: {
                          &quot;storageAccountType&quot;: &quot;Premium_LRS&quot;
                      }
                  }
              ]
          }
      },
      &quot;plan&quot;: {
          &quot;name&quot;: &quot;linuxdsvmubuntu&quot;,
          &quot;publisher&quot;: &quot;microsoft-ads&quot;,
          &quot;product&quot;: &quot;linux-data-science-vm-ubuntu&quot;
      }
  }
</code></pre><blockquote><p>The part of the ARM template that specifies the OS setup</p></blockquote><p>The important fields to look at are the way the <strong>imagReference</strong>, <strong>osDisk</strong> and <strong>dataDisks</strong> are created and the <strong>plan</strong> that is required if you want to deploy a marketplace VM. These differ from the vanilla setup that we get from the Terraform documentation. By going through the Terraform docs on the VM provider you can identify the fields necessary to turn the example VM into a Data Science VM. The main changes are to create a storage_data_disk that has the create_option = fromImageThis seems to be required as the DSVM ships with some data according to the ARM template. The second thing to add is the plan property into your VM recipe. This should be set with the same parameters as shown above in the ARM snippet.</p><p>You can find my final resulting code <a href=https://github.com/anoff/tf-azure-datascience/blob/8eff92fd4c8e609f6f938fe4230fcc940a1783d0/ds-vm.tf#L31>on github</a> üëØ‚Äç</p><h1 id=that-s-it-for-the-data-scientist-vm-now-on-to-the-file-share>That‚Äòs it for the Data Scientist VM, now on to the File share üìÑ</h1><p>Once you understand that the File service on Azure is part of the Storage suite you can either follow along the example above and look at the ARM template that the Portal generates or hop right into the <a href=https://www.terraform.io/docs/providers/azurerm/r/storage_share.html>Terraform documentation</a> and look for possible ways to deploy storage resources.</p><p>_Note: Before writing this article I didn‚Äôt realize there is an option to create a Fileshare using Terraform. So I initially built a <a href=https://github.com/anoff/tf-azure-datascience/blob/8eff92fd4c8e609f6f938fe4230fcc940a1783d0/provision_fileshare>custom Azure CLI script</a> and hooked that into the storage recipe. Take a look at the <a href=https://github.com/anoff/tf-azure-datascience/blob/8eff92fd4c8e609f6f938fe4230fcc940a1783d0/storage.tf#L15>code history</a> if you want to learn more about fusing Terraform with the Azure CLI._</p><p><img src=/assets/terraform-dsvm/tf_storage.png alt="Terraform resources for storage"></p><blockquote><p>Storage resources in the Azure Provider for Terraform</p></blockquote><p>Creating a recipe for the Fileshare is literally just copying the <a href=https://www.terraform.io/docs/providers/azurerm/r/storage_share.html#example-usage>example</a> as it does not have any customised properties. Make sure you give the whole setup pretty names and the correct quote and you‚Äôre done.</p><p><img src=/assets/terraform-dsvm/terraform_out.png alt="Terraform output during creation"></p><p>Run <code>terraform apply -auto-approve</code> to execute the recipe. In my latest run it took 2min 42sto spin up all the required resources.</p><p>Killing the components took twice as long üôÑ</p><p>The full recipe will provision the following 6 resources for you. You might notice that Terraform mentions 7 added resources, the difference of 1 comes from the resource group that is not listed below. If you want to clean up just run <code>terraform destroy</code>.</p><p><img src=/assets/terraform-dsvm/azure_rg.png alt="Azure resource group overview"></p><blockquote><p>Fully provisioned Datascience Setup</p></blockquote><h1 id=next-steps>Next steps üëü</h1><p>There‚Äôs a bunch of things I want to improve on this setup:</p><ol><li><p>Create a Terraform module for the Virtual Machine setup to easily create multiple VMs without cloning the 50+ lines recipe. The goal would be that the name of the VM, the size and the network can be defined. Ideally multiple data scientists would work in a common network.</p></li><li><p>Auto-mount the file share into the VMs during creation. The <a href=https://www.terraform.io/docs/provisioners/remote-exec.html>remote-exec provisioner</a> might be a good way to start.</p></li></ol><p>Feel free to discuss this approach or even implement improvements for this via a PR on github.com/anoff/tf-azure-datascience or on <a href=https://twitter.com/an0xff>twitter üê¶</a>. Hope you enjoyed my first article üï∫.</p></div><div class=footer><div class=tags><i class="fa fa-tags"></i><div class=links><a href=/tags/terraform>terraform</a>
<a href=/tags/azure>azure</a>
<a href=/tags/datascience>datascience</a></div></div></div></article></div><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"anoff-io"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><footer><div class=container><div class=right><div class=external-profiles><strong>Social media</strong>
<a href=//twitter.com/an0xff target=_blank><i class="fa fa-twitter-adblock-proof"></i></a><a href=//github.com/anoff target=_blank><i class="fa fa-github"></i></a><a href=//linkedin.com/in/offenhaeuser/ target=_blank><i class="fa fa-linkedin"></i></a></div></div></div></footer><div class=credits><div class=container><div class=copyright><a href=//anoff.io target=_blank>&copy;
2019
by Andreas Offenhaeuser</a></div><div class=author><a href=//github.com/Lednerb/bilberry-hugo-theme target=_blank>Bilberry Hugo Theme</a></div></div></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-93890295-4','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script type=text/javascript src=/js/externalDependencies.39c47e10e241eae2947b3fe21809c572.js integrity="md5-OcR&#43;EOJB6uKUez/iGAnFcg=="></script><script type=text/javascript src=/js/theme.ff50ae6dc1bfc220b23bf69dbb41b54e.js integrity="md5-/1CubcG/wiCyO/adu0G1Tg=="></script><script>$(".moment").each(function(){$(this).text(moment($(this).text()).locale("en").format('LL'));});$(".footnote-return sup").html("");</script><script src=//blog-gh.anoff.io/fix-adoc.js type=application/javascript></script><script src=//cdnjs.cloudflare.com/ajax/libs/cookieconsent2/3.1.0/cookieconsent.min.js type=application/javascript></script><script src=//blog-gh.anoff.io/init-cookieconsent.js type=application/javascript></script></body></html>